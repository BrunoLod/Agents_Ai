{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44v6Jh5ks7Kc"
      },
      "outputs": [],
      "source": [
        "class RAGToolInput(BaseModel):\n",
        "  # Input for RAG tool.\n",
        "\n",
        "  query: str = Field(description='Search query in vector database.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a ferramenta.\n",
        "\n",
        "class RAGTool(BaseTool):\n",
        "\n",
        "  name : str  = 'RAG Tool'\n",
        "  description : str = '''\n",
        "                      Tool for retrieving and generating answers using\n",
        "                      RAG from a vector store.\n",
        "                      '''\n",
        "  files_path: List[str] = []\n",
        "\n",
        "  args_schema: Type[BaseModel] = RAGToolInput\n",
        "\n",
        "  def _init__(self, model = model) -> None:\n",
        "\n",
        "    self.model = model\n",
        "    self.texts = self._load_and_split_files()\n",
        "    self.vector_db = self._create_vector_db()\n",
        "    self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "  def _load_files(self) -> list:\n",
        "\n",
        "    self.files_path = ['/content/psiAI/BroadViewofEffectsOfIntroducingGenerativeAIonPsychotherpy.pdf',\n",
        "                       '/content/psiAI/ConversationalBotsForPsychotherapy.pdf',\n",
        "                       '/content/psiAI/TheEvaluationOfGenerativeAIinPyschotherapy.pdf']\n",
        "\n",
        "    '''\n",
        "    Método que carrega os arquivos PDF e os divide em lotes,\n",
        "    para que possam ser armazenados de forma efetiva no banco\n",
        "    de dados vetorial.\n",
        "    '''\n",
        "\n",
        "    # Carrega e lê os PDF's.\n",
        "\n",
        "    all_text = []\n",
        "    for file_path in self.files_path:\n",
        "      reader = PdfReader(file_path)\n",
        "      text_extract = [p.extract_text() for p in reader.pages]\n",
        "      text = [text for text in text_extract if text]\n",
        "      all_text.extend(text)\n",
        "\n",
        "    return all_text\n",
        "\n",
        "  def _split_text(self, all_text : list) -> list:\n",
        "\n",
        "    recursive_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=2000,\n",
        "            chunk_overlap=150,\n",
        "            length_function=len,\n",
        "            separators=['\\n\\n', '\\n', '.', ' ', '']\n",
        "        )\n",
        "    text_splitted_rc = recursive_splitter.split_text('\\n\\n'.join(all_text))\n",
        "\n",
        "    token_splitter = SentenceTransformersTokenTextSplitter(\n",
        "            tokens_per_chunk=256,\n",
        "            chunk_overlap=0\n",
        "        )\n",
        "    token_split_text = []\n",
        "    for text in text_splitted_rc:\n",
        "      token_split_text += token_splitter.split_text(text)\n",
        "\n",
        "    return token_split_text\n",
        "\n",
        "  def _vector_db(self):\n",
        "\n",
        "      '''\n",
        "      Cria o banco de dados vetorial que irá armazenar os\n",
        "      documentos que poderão ser consultados.\n",
        "      '''\n",
        "      embedding_function = SentenceTransformerEmbeddingFunction()\n",
        "      chroma_client = chromadb.Client()\n",
        "      chroma_db = chroma_client.create_collection(\n",
        "          name='psychotherapy_and_AI',\n",
        "          embedding_function=embedding_function\n",
        "      )\n",
        "\n",
        "      ids = [str(i) for i in range(len(self.texts))]\n",
        "      chroma_db.add(ids=ids, documents=self.texts)\n",
        "\n",
        "      return chroma_db\n",
        "\n",
        "  def _argumented_multiple_query(self, query : str) -> str:\n",
        "\n",
        "    '''\n",
        "    Gera uma query expandida com base na original.\n",
        "    '''\n",
        "    template = PromptTemplate(\n",
        "            input_variables=['query'],\n",
        "            template='''\n",
        "            You are an experienced researcher on topics related to psychology and\n",
        "            psychotherapy with solid knowledge in generative AI and is studying the\n",
        "            existing and possible relationship of using generative AI in conducting\n",
        "            psychotherapy.\n",
        "\n",
        "            Your task is to suggest up to seven additional related questions\n",
        "            to help them find the information they need for the provided question.\n",
        "            Suggest only short questions without compound sentences.\n",
        "            Output one question per line.\n",
        "\n",
        "            Question: {query}\n",
        "\n",
        "            Helpful Answer:\n",
        "            '''\n",
        "        )\n",
        "\n",
        "    chain = LLMChain(llm=self.model, prompt=template)\n",
        "\n",
        "    return chain.invoke(input=query)\n",
        "\n",
        "  def _retrieve_documents(self, query : str) -> list:\n",
        "\n",
        "    '''\n",
        "    Realiza a pesquisa no banco de dados vetorial.\n",
        "    '''\n",
        "\n",
        "    expanded_query = f'{query}  {self.argumented_multiple_query(query)}'\n",
        "\n",
        "    results = self._vector_db().query(query_texts=expanded_query,\n",
        "                                   n_results=10,\n",
        "                                   include=['documents', 'embeddings'])\n",
        "\n",
        "    if not results['documents']:\n",
        "      return\n",
        "\n",
        "    else:\n",
        "      retrieved_documents = results['documents'][0]\n",
        "      pairs = [[query, doc] for doc in retrieved_documents]\n",
        "      scores = self.cross_encoder.predict(pairs)\n",
        "\n",
        "      documents_with_scores = list(zip(retrieved_documents, scores))\n",
        "      ranked_documents = sorted(documents_with_scores, key=lambda x: x[1],\n",
        "                                reverse=True)\n",
        "      top5_re_ranked_documents = [doc for doc, score in ranked_documents[:5]]\n",
        "\n",
        "      return top5_re_ranked_documents\n",
        "\n",
        "  def rag_response(self, query : str) -> str:\n",
        "\n",
        "    '''\n",
        "    Gera a resposta baseada nos documentos. Caso a pergunta do usuário\n",
        "    não apresente itens armazenados relacionados que consiga lhe prover\n",
        "    uma resposta, o modelo será instruído a não responder, instruindo\n",
        "    a utilizar outra ferramenta.\n",
        "    '''\n",
        "\n",
        "    retrieved_documents = self._retrieve_documents(query)\n",
        "\n",
        "    if not retrieved_documents:\n",
        "\n",
        "      suggestion = '''\n",
        "      Não há informações armazenadas no banco de dados vetorial para responder\n",
        "      a essa query. UTILIZE a ferramenta {tavily_search_tool} para responder ao\n",
        "      usuário de forma acurada.\n",
        "      '''\n",
        "      return suggestion\n",
        "\n",
        "    else:\n",
        "\n",
        "      information = '\\n\\n'.join(retrieved_documents)\n",
        "\n",
        "      prompt_template = PromptTemplate(\n",
        "          input_variables=['query', 'information'],\n",
        "          template='''\n",
        "          You are an experienced researcher on topics related to psychology and\n",
        "          psychotherapy with solid knowledge in generative AI and is studying the\n",
        "          existing and possible relationship of using generative AI in conducting\n",
        "          psychotherapy.\n",
        "\n",
        "          Your task is to respond clearly, didactically, and in detail to the user's query.\n",
        "          Answer the user's question using only the provided information and in Portuguese.\n",
        "\n",
        "          Question: {query}\n",
        "          Information: {information}\n",
        "\n",
        "          Helpful Answer:\n",
        "          '''\n",
        "          )\n",
        "\n",
        "      chain = LLMChain(llm=self.model, prompt=prompt_template)\n",
        "\n",
        "      response = chain.invoke(input={'query':query, 'information':information})\n",
        "\n",
        "      return response\n",
        "\n",
        "  def _run(self, query: str) -> str:\n",
        "\n",
        "    '''\n",
        "    Executa a ferramenta e retorna uma resposta baseada na pesquisa.\n",
        "    '''\n",
        "\n",
        "    return self.rag_response(query)\n",
        "\n"
      ],
      "metadata": {
        "id": "syDmLYHts_-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}